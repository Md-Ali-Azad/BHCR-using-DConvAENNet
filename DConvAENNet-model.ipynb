{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,cv2\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "import tensorflow\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, BatchNormalization, Input, Reshape, Flatten, Deconvolution2D, Conv2DTranspose, MaxPooling2D, UpSampling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import SGD,RMSprop,adam\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<----------------------Load Train Images--------------------->\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "data_path='C:/Users/admin/Documents/CMATERdb/C_full/Train'\n",
    "data_dir_list = os.listdir(data_path)\n",
    "img_rows=28\n",
    "img_cols=28\n",
    "num_channel=1\n",
    "num_classes = 238\n",
    "\n",
    "labels_name={}\n",
    "for i in range(num_classes):\n",
    "    #labels_name[str(i)]=i\n",
    "    labels_name[str(i+1)]=i\n",
    "print(labels_name)\n",
    "img_data_list=[]\n",
    "labels_list = []\n",
    "for dataset in data_dir_list:\n",
    "\timg_list=os.listdir(data_path+'/'+ dataset)\n",
    "\tprint ('Loading the images of dataset-'+'{}\\n'.format(dataset))\n",
    "\tlabel = labels_name[dataset]\n",
    "\tprint(label)\n",
    "\tfor img in img_list:\n",
    "\t\tinput_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\n",
    "\t\tinput_img=cv2.cvtColor(input_img,cv2.COLOR_BGR2GRAY)\n",
    "\t\tinput_img_resize=cv2.resize(input_img,(img_rows,img_cols))\n",
    "\t\timg_data_list.append(input_img_resize)\n",
    "\t\tlabels_list.append(label)\n",
    "img_data = np.array(img_data_list)\n",
    "img_data = img_data.astype('float32')\n",
    "img_data /= 255\n",
    "print (img_data.shape)\n",
    "\n",
    "labels = np.array(labels_list)\n",
    "print(np.unique(labels,return_counts=True))\n",
    "Y = np_utils.to_categorical(labels, num_classes)\n",
    "\n",
    "\n",
    "x,y = shuffle(img_data,Y, random_state=2)\n",
    "\n",
    "X_train=x\n",
    "y_train=y\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "print('input_shape_train: ', input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#<----------------------Load Test-Validation Images / Cross Test & Validation Images--------------------->\n",
    "data_path2 ='C:/Users/admin/Documents/CMATERdb/C_full/Test'\n",
    "data_dir_list2 = os.listdir(data_path2)\n",
    "img_rows2=28\n",
    "img_cols2=28\n",
    "\n",
    "num_classes2 = 238\n",
    "\n",
    "labels_name2={}\n",
    "for i in range(num_classes2):\n",
    "    #labels_name2[str(i)]=i\n",
    "    labels_name2[str(i+1)]=i\n",
    "\n",
    "print(labels_name2)\n",
    "img_data_list2=[]\n",
    "labels_list2 = []\n",
    "for dataset2 in data_dir_list2:\n",
    "\timg_list2=os.listdir(data_path2+'/'+ dataset2)\n",
    "\tprint ('Loading the images of dataset-'+'{}\\n'.format(dataset2))\n",
    "\tlabel2 = labels_name2[dataset2]\n",
    "\tprint(label2)\n",
    "\tfor img2 in img_list2:\n",
    "\t\tinput_img2=cv2.imread(data_path2 + '/'+ dataset2 + '/'+ img2 )\n",
    "\t\tinput_img2=cv2.cvtColor(input_img2,cv2.COLOR_BGR2GRAY)\n",
    "\t\tinput_img_resize2=cv2.resize(input_img2,(img_rows2,img_cols2))\n",
    "\t\timg_data_list2.append(input_img_resize2)\n",
    "\t\tlabels_list2.append(label2)\n",
    "img_data2 = np.array(img_data_list2)\n",
    "img_data2 = img_data2.astype('float32')\n",
    "img_data2 /= 255\n",
    "print (img_data2.shape)\n",
    "\n",
    "labels2 = np.array(labels_list2)\n",
    "print(np.unique(labels2,return_counts=True))\n",
    "Y2 = np_utils.to_categorical(labels2, num_classes2)\n",
    "\n",
    "x2,y2 = shuffle(img_data2,Y2, random_state=2)\n",
    "X_vali2, X_test2, y_vali2, y_test2 = train_test_split(x2, y2, test_size=0.5, random_state=2)\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_test2 = X_test2.reshape(X_test2.shape[0], 1, img_rows2, img_cols2)\n",
    "    input_shape2 = (1, img_rows2, img_cols2)\n",
    "else:\n",
    "    x_test2 = X_test2.reshape(X_test2.shape[0], img_rows2, img_cols2, 1)\n",
    "    input_shape2 = (img_rows2, img_cols2, 1)\n",
    "\n",
    "print('input_shape_test_vali: ', input_shape2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h = img_rows, img_cols\n",
    "input_img = Input(shape = (w, h, num_channel))\n",
    "#<----------------------DConvAENNet PART 1: UNSUPERVISED LEARNING (ENCODER)--------------------->\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Dropout(0.35)(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "Encoder = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "#<-----------------------DConvAENNet PART 2: UNSUPERVISED LEARNING (DECODER)---------------------->\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(Encoder)\n",
    "x = Dropout(0.35)(x)\n",
    "x = Conv2D(64, (3, 3),activation='relu', padding='same')(x)\n",
    "x = Conv2D(128 , (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((7, 7))(x)\n",
    "Decoder = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "Auto_Encoder = Model(input_img, Decoder)\n",
    "Auto_Encoder.compile(optimizer='RMSprop', loss='binary_crossentropy',metrics=['accuracy'])\n",
    "Auto_Encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1,img_rows, img_cols, 1)   \n",
    "X_vali2 = X_vali2.reshape(-1,img_rows, img_cols, 1)   \n",
    "X_test2 = X_test2.reshape(-1,img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Datagen = ImageDataGenerator( rotation_range=0.2, width_shift_range=0.2, height_shift_range=0.2 )\n",
    "Datagen.fit(X_train,augment=True)\n",
    "Auto_Encoder.fit_generator(Datagen.flow(X_train, X_train, batch_size=112,shuffle=True), epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<---------------------Augmented Images-------------------------->\n",
    "import matplotlib.pyplot as plt\n",
    "for X_batch, y_batch in Datagen.flow(X_train, y_train, batch_size=112):\n",
    "\tfor i in range(0, 9):\n",
    "\t\tplt.subplot(330 + 1 + i)\n",
    "\t\tplt.imshow(X_batch[i].reshape(28, 28), cmap=plt.get_cmap('gray'))\n",
    "\tplt.show()\n",
    "\tbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#<--------------------DConvAENNet PART 3: SUPERVISED LEARNING (ENCODER AND FULLY CONNECTED DENSE LAYERS)------------------>\n",
    "x=Flatten()(Encoder)\n",
    "x=Dense(3*num_classes,activation='relu')(x)                \n",
    "x=Dense(num_classes,activation='softmax')(x)\n",
    "MODEL=Model([input_img],[x])\n",
    "MODEL.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
    "MODEL.summary()\n",
    "super_train_aug = ImageDataGenerator(rotation_range=0.0,width_shift_range=0.0,height_shift_range=0.0)\n",
    "super_train_aug.fit(X_train, augment=True)\n",
    "super_test_aug = ImageDataGenerator()\n",
    "super_test_aug.fit(X_test2, augment=True)\n",
    "super_train = super_train_aug.flow(X_train, y_train,batch_size=112)                   \n",
    "super_vali = super_test_aug.flow(X_vali2, y_vali2,batch_size=112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history=MODEL.fit_generator(super_train,epochs=50,validation_data=super_vali,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = MODEL.evaluate(X_test2,y_test2, verbose=0)\n",
    "print(\"DConvAENNet Testing Accuracy: %.2f%%\" % (score[1]*100))\n",
    "print(\"DConvAENNet Testing Error: %.2f%%\" % (100-score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Keys: \")\n",
    "print(history.history.keys())\n",
    "print(\"Train Accuracy: \")\n",
    "print(history.history['accuracy'])\n",
    "print(\"Val. Accuracy: \")\n",
    "print(history.history['val_accuracy'])\n",
    "\n",
    "print(\"Train Loss: \")\n",
    "print(history.history['loss'])\n",
    "print(\"Val. Loss: \")\n",
    "print(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#<--------------------Classification Report-------------------->\n",
    "from sklearn.metrics import classification_report\n",
    "Y_test = np.argmax(y_test2, axis=1)\n",
    "y_pred = MODEL.predict(X_test2)\n",
    "print(classification_report(Y_test, np.argmax(y_pred, axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#<--------------------Generate Confusion Matrix-------------------->\n",
    "import sklearn\n",
    "matrix = sklearn.metrics.confusion_matrix(Y_test, np.argmax(y_pred, axis = 1))\n",
    "print(matrix)\n",
    "import sys\n",
    "import numpy\n",
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "print(np.array(matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<--------------------Plot Confusion Matrix -------------------->\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "df_cm = pd.DataFrame(matrix, range(num_classes), range(num_classes))\n",
    "sn.set(font_scale=1.4)\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 6})\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<-------------------- serialize model to JSON ---------------------->\n",
    "model_json = MODEL.to_json()\n",
    "with open(\"model_name.json\", \"w\") as json_file:\n",
    "\tjson_file.write(model_json)\n",
    "#<-------------------- serialize weights to HDF5 ---------------------->\n",
    "MODEL.save_weights(\"model_name.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<-------------------- Plot histroy -------------------->\n",
    "import matplotlib.pyplot as plt\n",
    "print(history.history.keys())\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Accuracy vs Iteration')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Iteration')\n",
    "plt.legend(['train', 'test'], loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Loss vs Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
